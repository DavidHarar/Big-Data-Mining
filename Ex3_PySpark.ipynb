{"cells":[{"cell_type":"markdown","source":["# Problem Set 3: Spark\n### Instructions: Upload the file to databrcks community edition. Fill the code and text in the designated places and submit a filled .ipynb in moodle by 10/6/2021\n### There are 10 questions overall. Each question is worth 10 points. The questions vary significantly in length and difficulty. \n### You should use apache spark commands, in addition to python code where needed\n### The file contains small functions and other lines of code that will help you solve the exercise. You may copy and/or modify them as you wish\n### Good luck"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b80a97f9-77b8-4ce7-87da-16f625cdfd50"}}},{"cell_type":"markdown","source":["###  Part 1): Finding Prime Numbers with Spark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91ab1a73-455c-4466-8005-39474feea0c6"}}},{"cell_type":"code","source":["# Class used for timing your commands\nimport time\nclass Timer(object):\n    def __init__(self, name=None):\n        self.name = name\n\n    def __enter__(self):\n        self.tstart = time.time()\n\n    def __exit__(self, type, value, traceback):\n        if self.name:\n            print('[%s]' % self.name,)\n        print('Elapsed: %s' % (time.time() - self.tstart))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d72b7f00-e653-43af-9f62-929a47298ea5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 1:** Write a **python** function that given a natural number n returns True/False if the number is prime or not by checking its factors (divisors) up to a sqrt(n). <br>\nTest the function on the first 100 natural numbers. <br>\nWhat is the O(f(n)) complexity of this algorithm for finding all primes up to n as a function of n? (assume that arithmatic operations take O(1) regardless of the size of the numbers)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f63e2f39-92a6-4f0c-b234-297363928428"}}},{"cell_type":"code","source":["import numpy as np\n\n# SOLUTION\ndef check_prime(n):\n  # a convension\n  if n == 1: return False \n  # skipping 2 so we could use the while and start from\n  # t = 2\n  if n == 2: return True\n  t = 2\n  while (n % t) != 0:\n    if t >= np.sqrt(n):\n      return True \n    t += 1\n  return False\n\n# Running on the first 100 numbers\nfor j in range(100):\n  print(f'check if {j+1} is a prime number, result: {check_prime(j+1)}.')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fff12ab6-c5a2-448e-ac1e-8a4e7d851b23"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">check if 1 is a prime number, result: False.\ncheck if 2 is a prime number, result: True.\ncheck if 3 is a prime number, result: True.\ncheck if 4 is a prime number, result: False.\ncheck if 5 is a prime number, result: True.\ncheck if 6 is a prime number, result: False.\ncheck if 7 is a prime number, result: True.\ncheck if 8 is a prime number, result: False.\ncheck if 9 is a prime number, result: False.\ncheck if 10 is a prime number, result: False.\ncheck if 11 is a prime number, result: True.\ncheck if 12 is a prime number, result: False.\ncheck if 13 is a prime number, result: True.\ncheck if 14 is a prime number, result: False.\ncheck if 15 is a prime number, result: False.\ncheck if 16 is a prime number, result: False.\ncheck if 17 is a prime number, result: True.\ncheck if 18 is a prime number, result: False.\ncheck if 19 is a prime number, result: True.\ncheck if 20 is a prime number, result: False.\ncheck if 21 is a prime number, result: False.\ncheck if 22 is a prime number, result: False.\ncheck if 23 is a prime number, result: True.\ncheck if 24 is a prime number, result: False.\ncheck if 25 is a prime number, result: False.\ncheck if 26 is a prime number, result: False.\ncheck if 27 is a prime number, result: False.\ncheck if 28 is a prime number, result: False.\ncheck if 29 is a prime number, result: True.\ncheck if 30 is a prime number, result: False.\ncheck if 31 is a prime number, result: True.\ncheck if 32 is a prime number, result: False.\ncheck if 33 is a prime number, result: False.\ncheck if 34 is a prime number, result: False.\ncheck if 35 is a prime number, result: False.\ncheck if 36 is a prime number, result: False.\ncheck if 37 is a prime number, result: True.\ncheck if 38 is a prime number, result: False.\ncheck if 39 is a prime number, result: False.\ncheck if 40 is a prime number, result: False.\ncheck if 41 is a prime number, result: True.\ncheck if 42 is a prime number, result: False.\ncheck if 43 is a prime number, result: True.\ncheck if 44 is a prime number, result: False.\ncheck if 45 is a prime number, result: False.\ncheck if 46 is a prime number, result: False.\ncheck if 47 is a prime number, result: True.\ncheck if 48 is a prime number, result: False.\ncheck if 49 is a prime number, result: False.\ncheck if 50 is a prime number, result: False.\ncheck if 51 is a prime number, result: False.\ncheck if 52 is a prime number, result: False.\ncheck if 53 is a prime number, result: True.\ncheck if 54 is a prime number, result: False.\ncheck if 55 is a prime number, result: False.\ncheck if 56 is a prime number, result: False.\ncheck if 57 is a prime number, result: False.\ncheck if 58 is a prime number, result: False.\ncheck if 59 is a prime number, result: True.\ncheck if 60 is a prime number, result: False.\ncheck if 61 is a prime number, result: True.\ncheck if 62 is a prime number, result: False.\ncheck if 63 is a prime number, result: False.\ncheck if 64 is a prime number, result: False.\ncheck if 65 is a prime number, result: False.\ncheck if 66 is a prime number, result: False.\ncheck if 67 is a prime number, result: True.\ncheck if 68 is a prime number, result: False.\ncheck if 69 is a prime number, result: False.\ncheck if 70 is a prime number, result: False.\ncheck if 71 is a prime number, result: True.\ncheck if 72 is a prime number, result: False.\ncheck if 73 is a prime number, result: True.\ncheck if 74 is a prime number, result: False.\ncheck if 75 is a prime number, result: False.\ncheck if 76 is a prime number, result: False.\ncheck if 77 is a prime number, result: False.\ncheck if 78 is a prime number, result: False.\ncheck if 79 is a prime number, result: True.\ncheck if 80 is a prime number, result: False.\ncheck if 81 is a prime number, result: False.\ncheck if 82 is a prime number, result: False.\ncheck if 83 is a prime number, result: True.\ncheck if 84 is a prime number, result: False.\ncheck if 85 is a prime number, result: False.\ncheck if 86 is a prime number, result: False.\ncheck if 87 is a prime number, result: False.\ncheck if 88 is a prime number, result: False.\ncheck if 89 is a prime number, result: True.\ncheck if 90 is a prime number, result: False.\ncheck if 91 is a prime number, result: False.\ncheck if 92 is a prime number, result: False.\ncheck if 93 is a prime number, result: False.\ncheck if 94 is a prime number, result: False.\ncheck if 95 is a prime number, result: False.\ncheck if 96 is a prime number, result: False.\ncheck if 97 is a prime number, result: True.\ncheck if 98 is a prime number, result: False.\ncheck if 99 is a prime number, result: False.\ncheck if 100 is a prime number, result: False.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">check if 1 is a prime number, result: False.\ncheck if 2 is a prime number, result: True.\ncheck if 3 is a prime number, result: True.\ncheck if 4 is a prime number, result: False.\ncheck if 5 is a prime number, result: True.\ncheck if 6 is a prime number, result: False.\ncheck if 7 is a prime number, result: True.\ncheck if 8 is a prime number, result: False.\ncheck if 9 is a prime number, result: False.\ncheck if 10 is a prime number, result: False.\ncheck if 11 is a prime number, result: True.\ncheck if 12 is a prime number, result: False.\ncheck if 13 is a prime number, result: True.\ncheck if 14 is a prime number, result: False.\ncheck if 15 is a prime number, result: False.\ncheck if 16 is a prime number, result: False.\ncheck if 17 is a prime number, result: True.\ncheck if 18 is a prime number, result: False.\ncheck if 19 is a prime number, result: True.\ncheck if 20 is a prime number, result: False.\ncheck if 21 is a prime number, result: False.\ncheck if 22 is a prime number, result: False.\ncheck if 23 is a prime number, result: True.\ncheck if 24 is a prime number, result: False.\ncheck if 25 is a prime number, result: False.\ncheck if 26 is a prime number, result: False.\ncheck if 27 is a prime number, result: False.\ncheck if 28 is a prime number, result: False.\ncheck if 29 is a prime number, result: True.\ncheck if 30 is a prime number, result: False.\ncheck if 31 is a prime number, result: True.\ncheck if 32 is a prime number, result: False.\ncheck if 33 is a prime number, result: False.\ncheck if 34 is a prime number, result: False.\ncheck if 35 is a prime number, result: False.\ncheck if 36 is a prime number, result: False.\ncheck if 37 is a prime number, result: True.\ncheck if 38 is a prime number, result: False.\ncheck if 39 is a prime number, result: False.\ncheck if 40 is a prime number, result: False.\ncheck if 41 is a prime number, result: True.\ncheck if 42 is a prime number, result: False.\ncheck if 43 is a prime number, result: True.\ncheck if 44 is a prime number, result: False.\ncheck if 45 is a prime number, result: False.\ncheck if 46 is a prime number, result: False.\ncheck if 47 is a prime number, result: True.\ncheck if 48 is a prime number, result: False.\ncheck if 49 is a prime number, result: False.\ncheck if 50 is a prime number, result: False.\ncheck if 51 is a prime number, result: False.\ncheck if 52 is a prime number, result: False.\ncheck if 53 is a prime number, result: True.\ncheck if 54 is a prime number, result: False.\ncheck if 55 is a prime number, result: False.\ncheck if 56 is a prime number, result: False.\ncheck if 57 is a prime number, result: False.\ncheck if 58 is a prime number, result: False.\ncheck if 59 is a prime number, result: True.\ncheck if 60 is a prime number, result: False.\ncheck if 61 is a prime number, result: True.\ncheck if 62 is a prime number, result: False.\ncheck if 63 is a prime number, result: False.\ncheck if 64 is a prime number, result: False.\ncheck if 65 is a prime number, result: False.\ncheck if 66 is a prime number, result: False.\ncheck if 67 is a prime number, result: True.\ncheck if 68 is a prime number, result: False.\ncheck if 69 is a prime number, result: False.\ncheck if 70 is a prime number, result: False.\ncheck if 71 is a prime number, result: True.\ncheck if 72 is a prime number, result: False.\ncheck if 73 is a prime number, result: True.\ncheck if 74 is a prime number, result: False.\ncheck if 75 is a prime number, result: False.\ncheck if 76 is a prime number, result: False.\ncheck if 77 is a prime number, result: False.\ncheck if 78 is a prime number, result: False.\ncheck if 79 is a prime number, result: True.\ncheck if 80 is a prime number, result: False.\ncheck if 81 is a prime number, result: False.\ncheck if 82 is a prime number, result: False.\ncheck if 83 is a prime number, result: True.\ncheck if 84 is a prime number, result: False.\ncheck if 85 is a prime number, result: False.\ncheck if 86 is a prime number, result: False.\ncheck if 87 is a prime number, result: False.\ncheck if 88 is a prime number, result: False.\ncheck if 89 is a prime number, result: True.\ncheck if 90 is a prime number, result: False.\ncheck if 91 is a prime number, result: False.\ncheck if 92 is a prime number, result: False.\ncheck if 93 is a prime number, result: False.\ncheck if 94 is a prime number, result: False.\ncheck if 95 is a prime number, result: False.\ncheck if 96 is a prime number, result: False.\ncheck if 97 is a prime number, result: True.\ncheck if 98 is a prime number, result: False.\ncheck if 99 is a prime number, result: False.\ncheck if 100 is a prime number, result: False.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**SOLUTION <br>**\nO(n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"941fb9a5-2409-4bfc-a6a4-4dc2f5c7b4a2"}}},{"cell_type":"markdown","source":["**Question 2:** Create a range object of various sizes starting at 10 up to 10 millions (by a factor of 10, i.e. 10 ,100, 1000 .. etc up to 10 millions) and test your function in (a) in two ways: <br> \n- First, use native python for the range <br>\n- Second, use a Spark RDD for the range <br>\nCompare and print the running times (in seconds, rounded to 2 decimal points) of each methodology (Spark vs. python) for each `n`. <br>\nFor what values of `n` is the RDD is better (we call this order the `breaking point order`) ? Why do you think spark/python is faster before/after? <br>\n*Note:* The answer may vary from run to run and depending on the number of cores available when running using Spark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5d784f4-af64-4a34-b89b-d54e4b5af2c7"}}},{"cell_type":"code","source":["# SOLUTION\n# NOTE: I rounded the duration into 2 decimal points, but because the calculation was fast\n# and resulted in something like 0.000X, the round function has rounded it to 0.0.\n\nrange_10 = list(np.arange(1,10+1))\nrange_100 = list(np.arange(1,100+1))\nrange_1000 = list(np.arange(1,1000+1))\nrange_10000 = list(np.arange(1,10000+1))\nrange_100000 = list(np.arange(1,100000+1))\nrange_1000000 = list(np.arange(1,1000000+1))\nrange_10000000 = list(np.arange(1,10000000+1))\n\n# Durations in Python\ndurations_python = dict({\n  'length_10':[],\n  'length_100':[],\n  'length_1000':[],\n  'length_10000':[],\n  'length_100000':[],\n  'length_1000000':[],\n  'length_10000000':[]  \n})\n\nstart = time.time()\nfor j in range_10:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_10'].append(round((end - start),2))\n\nstart = time.time()\nfor j in range_100:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_100'].append(round((end - start),2))\n\nstart = time.time()\nfor j in range_1000:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_1000'].append(round((end - start),2))\n\nstart = time.time()\nfor j in range_10000:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_10000'].append(round((end - start),2))\n\nstart = time.time()\nfor j in range_100000:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_100000'].append(round((end - start),2))\n\nstart = time.time()\nfor j in range_1000000:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_1000000'].append(round((end - start),2))\n\nstart = time.time()\nfor j in range_10000000:\n  result = check_prime(j)\nend = time.time()\ndurations_python['length_10000000'].append(round((end - start),2))\n\nprint(f'Python Durations: {durations_python}')\n\n# Durations in Scala\ndurations_scala = dict({\n  'length_10':[],\n  'length_100':[],\n  'length_1000':[],\n  'length_10000':[],\n  'length_100000':[],\n  'length_1000000':[],\n  'length_10000000':[]  \n})\n\n# SPARK SCALA PARALLEL RANGE:\nrange_10_sc = sc.parallelize(range_10)\nrange_100_sc = sc.parallelize(range_100)\nrange_1000_sc = sc.parallelize(range_1000)\nrange_10000_sc = sc.parallelize(range_10000)\nrange_100000_sc = sc.parallelize(range_100000)\nrange_1000000_sc = sc.parallelize(range_1000000)\nrange_10000000_sc = sc.parallelize(range_10000000)\n\nstart = time.time()\nresult = range_10_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_10'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_100_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_100'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_1000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_1000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_10000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_10000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_100000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_100000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_1000000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_1000000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_10000000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala['length_10000000'].append(round((end - start),2))\n\nprint(f'Scala Durations: {durations_scala}')\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3bc57d73-6260-4a97-88a6-bc7aafa120ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python Durations: {&#39;length_10&#39;: [0.0], &#39;length_100&#39;: [0.0], &#39;length_1000&#39;: [0.02], &#39;length_10000&#39;: [0.38], &#39;length_100000&#39;: [9.16], &#39;length_1000000&#39;: [214.68], &#39;length_10000000&#39;: [5600.76]}\nScala Durations: {&#39;length_10&#39;: [0.0], &#39;length_100&#39;: [0.0], &#39;length_1000&#39;: [0.0], &#39;length_10000&#39;: [0.0], &#39;length_100000&#39;: [0.0], &#39;length_1000000&#39;: [0.0], &#39;length_10000000&#39;: [0.0]}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python Durations: {&#39;length_10&#39;: [0.0], &#39;length_100&#39;: [0.0], &#39;length_1000&#39;: [0.02], &#39;length_10000&#39;: [0.38], &#39;length_100000&#39;: [9.16], &#39;length_1000000&#39;: [214.68], &#39;length_10000000&#39;: [5600.76]}\nScala Durations: {&#39;length_10&#39;: [0.0], &#39;length_100&#39;: [0.0], &#39;length_1000&#39;: [0.0], &#39;length_10000&#39;: [0.0], &#39;length_100000&#39;: [0.0], &#39;length_1000000&#39;: [0.0], &#39;length_10000000&#39;: [0.0]}\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["### Test for the same output ###\n# Looking at the durations above, we see that independently on the length of the vector at hand, the \n# parallelized version took less than a second. I added this section in order to verify that they both\n# return the same output. IT SHOWS THEY DO.\n\ntest_list_sequentional = []\nfor j in list(np.arange(1,100+1)):\n  test_list_sequentional.append(int(check_prime(j)))\n\nrange_100_sc = sc.parallelize(range_100)\nstart = time.time()\nresult = range_100_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ntest_list_parallel = result.take(100)\n\ntest_list_sequentional == test_list_parallel\n# That seems that the outputs are the same."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3de4c0ee-ae5e-4c68-b012-7849f78ed277"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[139]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[139]: True</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**SOLUTION** <br>\nIt seems that the breaking point order is in around 1000. From `n=1000`, Scala showed faster solution for the same objects."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0b4c153-02dc-4902-8283-e8b3ba0c447c"}}},{"cell_type":"markdown","source":["**Question 3:** When splitting the spark range array into different nodes, each nodes will get a consecutive sub-range in standard spark implementations. <br> \nTherefore, it is possible that different nodes will get ranges of numbers of different difficulty (for example, one node may get small, easier numbers, and another may get large, harder numbers). <br>\nThis may cause imbalance between the workload of the nodes and slow down the overall computation. \nHow would you change the Spark implementation such that nodes faster (without changing the function testing primality)? <br>\nImplementing the change in Spark RDD, repeat the computation for the same values of `n` as in the previous question and compare the computation times. <br>\nNote that because we are using the free-tier of databricks, the available cluster only has 1 node, so the actual gain in running time might not be aparent."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26b6fe19-573e-42cf-9a3b-f401d0aa28a5"}}},{"cell_type":"markdown","source":["**SOLUTION** <br>\nEntering an ordered range of numbers between `1` and `n` into the algorithm results in unbalanced inputs in computation complexity. As `i` (from the range 1:n) grows, computation complexity to check whether `i` is a prime number grows as well.  \nOne way to relax the imbalance between different nodes' workload is to assign low-complexity numbers (smaller ones) with high-complexity numbers (larger `i`'s). Specifically, to assign (n,1) to the first node, (n-1,2) to the second, and so on.  \nA much easier way to distribute the workload more evenly is to shuffle the numbers in the range. It probably may result in a higher imbalance in comparison with the above matching method. Still, it should be faster than the naive way presented in the previous sub-section."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b568f725-8518-4222-bf68-20d67d9bf37c"}}},{"cell_type":"code","source":["# SOLUTION\nimport random\n\n# Create sequences\nrange_10 = list(np.arange(1,10+1))\nrange_100 = list(np.arange(1,100+1))\nrange_1000 = list(np.arange(1,1000+1))\nrange_10000 = list(np.arange(1,10000+1))\nrange_100000 = list(np.arange(1,100000+1))\nrange_1000000 = list(np.arange(1,1000000+1))\nrange_10000000 = list(np.arange(1,10000000+1))\nrandom.shuffle(range_10)\nrandom.shuffle(range_100)\nrandom.shuffle(range_1000)\nrandom.shuffle(range_10000)\nrandom.shuffle(range_100000)\nrandom.shuffle(range_1000000)\nrandom.shuffle(range_10000000)\n\n# SPARK SCALA PARALLEL RANGE:\nrange_10_sc = sc.parallelize(range_10)\nrange_100_sc = sc.parallelize(range_100)\nrange_1000_sc = sc.parallelize(range_1000)\nrange_10000_sc = sc.parallelize(range_10000)\nrange_100000_sc = sc.parallelize(range_100000)\nrange_1000000_sc = sc.parallelize(range_1000000)\nrange_10000000_sc = sc.parallelize(range_10000000)\n\ndurations_scala_random = dict({\n  'length_10':[],\n  'length_100':[],\n  'length_1000':[],\n  'length_10000':[],\n  'length_100000':[],\n  'length_1000000':[],\n  'length_10000000':[]  \n})\n\nstart = time.time()\nresult = range_10_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_10'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_100_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_100'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_1000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_1000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_10000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_10000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_100000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_100000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_1000000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_1000000'].append(round((end - start),2))\n\nstart = time.time()\nresult = range_10000000_sc.map(lambda x: round(check_prime(x),2))\nend = time.time()\ndurations_scala_random['length_10000000'].append(round((end - start),2))\n\nprint(f'Scala Durations Random: {durations_scala_random}')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e549f580-1fa5-41f1-8357-70a1666e341a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Scala Durations Random: {&#39;length_10&#39;: [0.0], &#39;length_100&#39;: [0.0], &#39;length_1000&#39;: [0.0], &#39;length_10000&#39;: [0.0], &#39;length_100000&#39;: [0.0], &#39;length_1000000&#39;: [0.0], &#39;length_10000000&#39;: [0.0]}\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Scala Durations Random: {&#39;length_10&#39;: [0.0], &#39;length_100&#39;: [0.0], &#39;length_1000&#39;: [0.0], &#39;length_10000&#39;: [0.0], &#39;length_100000&#39;: [0.0], &#39;length_1000000&#39;: [0.0], &#39;length_10000000&#39;: [0.0]}\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 4:** Write a **python** function that implements Eratosthenes Sieve: given a natural integer `n`, finds all the primes up to that number by iterating over all the numbers larger than `1` in increasing order, and for each number (say i), crossing out all multiples of `i`. <br>\nBy doing so for all the numbers between 2 and `sqrt(n)`, we will end up with only prime numbers. <br>\nTest your function using the same values of `n` from the previous questions with native  python and report the running time in seconds as previously done. What is the `O()` complexity of finding all primes up to `n` as a function of `n`?  how does it compare to the previous method?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd1a733d-71f0-4fcc-baba-df4d91a99134"}}},{"cell_type":"code","source":["# SOLUTION\ndef Eratosthenes(n):\n  primes = []\n  multiplications = []\n  for i in range(2,n+1):\n    if i in multiplications:\n      continue\n    # update multiplications list:\n    j = 1\n    while j*i <= np.sqrt(n):\n      multiplications.append(j*i)\n      j += 1\n    # is prime?\n    if check_prime(i):\n      primes.append(i)\n    else:\n      continue \n  return primes\n\n# RUN AND RECORD TIME\nwith Timer('Iteratively, length: 10'):\n  [check_prime(x) for x in range(2, 11)]\nwith Timer('Eratosthenes, length: 10'):\n  Eratosthenes(11)\n\nwith Timer('Iteratively, length: 100'):\n  [check_prime(x) for x in range(2, 101)]\nwith Timer('Eratosthenes, length: 100'):\n  Eratosthenes(101)\n\nwith Timer('Iteratively, length: 1000'):\n  [check_prime(x) for x in range(2, 1001)]\nwith Timer('Eratosthenes, length: 1000'):\n  Eratosthenes(1001)\n\nwith Timer('Iteratively, length: 10000'):\n  [check_prime(x) for x in range(2, 10001)]\nwith Timer('Eratosthenes, length: 10000'):\n  Eratosthenes(10001)\n\nwith Timer('Iteratively, length: 100000'):\n  [check_prime(x) for x in range(2, 100001)]\nwith Timer('Eratosthenes, length: 100000'):\n  Eratosthenes(100001)\n\nwith Timer('Iteratively, length: 1000000'):\n  [check_prime(x) for x in range(2, 1000001)]\nwith Timer('Eratosthenes, length: 1000000'):\n  Eratosthenes(1000001)\n\nwith Timer('Iteratively, length: 10000000'):\n  [check_prime(x) for x in range(2, 10000001)]\nwith Timer('Eratosthenes, length: 10000000'):\n  Eratosthenes(10000001)\n\n# We see that even though we run using a regular python syntax, the running times were shorten significantly using this new algorithm."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e10f40f-c776-4108-8a5c-8b89c6244847"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[Iteratively, length: 10]\nElapsed: 0.0001068115234375\n[Eratosthenes, length: 10]\nElapsed: 0.00011467933654785156\n[Iteratively, length: 100]\nElapsed: 0.00042748451232910156\n[Eratosthenes, length: 100]\nElapsed: 0.0006096363067626953\n[Iteratively, length: 1000]\nElapsed: 0.00842428207397461\n[Eratosthenes, length: 1000]\nElapsed: 0.011148691177368164\n[Iteratively, length: 10000]\nElapsed: 0.21086764335632324\n[Eratosthenes, length: 10000]\nElapsed: 0.2459118366241455\n[Iteratively, length: 100000]\nElapsed: 4.928882122039795\n[Eratosthenes, length: 100000]\nElapsed: 6.100539922714233\n[Iteratively, length: 1000000]\nElapsed: 126.57128810882568\n[Eratosthenes, length: 1000000]\nElapsed: 165.37500262260437\n[Iteratively, length: 10000000]\nElapsed: 3311.0633659362793\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[Iteratively, length: 10]\nElapsed: 0.0001068115234375\n[Eratosthenes, length: 10]\nElapsed: 0.00011467933654785156\n[Iteratively, length: 100]\nElapsed: 0.00042748451232910156\n[Eratosthenes, length: 100]\nElapsed: 0.0006096363067626953\n[Iteratively, length: 1000]\nElapsed: 0.00842428207397461\n[Eratosthenes, length: 1000]\nElapsed: 0.011148691177368164\n[Iteratively, length: 10000]\nElapsed: 0.21086764335632324\n[Eratosthenes, length: 10000]\nElapsed: 0.2459118366241455\n[Iteratively, length: 100000]\nElapsed: 4.928882122039795\n[Eratosthenes, length: 100000]\nElapsed: 6.100539922714233\n[Iteratively, length: 1000000]\nElapsed: 126.57128810882568\n[Eratosthenes, length: 1000000]\nElapsed: 165.37500262260437\n[Iteratively, length: 10000000]\nElapsed: 3311.0633659362793\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["*SOLUTION* <BR>\n`Eratosthenes` has complexity of `O(nlogn)`, which is faster in comparisson with finding all the prime numbers from `2` to `n` using a for loop with `check_prime()`. Writing a function that loop through `2:n` and che for every `i` whether it is a prime number would have the complexity of `O(n^2)`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed3812c9-9fdf-429b-b722-b0e158035ee1"}}},{"cell_type":"markdown","source":["**Question 5:** Can you implement the algorithm in Question 4 in a parallel implementation using Spark? If not, explain why, if yes, please do so and run for the same values of `n` as in the previous question"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b497411-2fd2-4860-8ee2-687b47997928"}}},{"cell_type":"code","source":["# SOLUTION\ndef Eratosthenes_sc(n):\n  I = sc.parallelize(list(range(2,n+1)))\n  Ij = I.map(lambda x: (x, list(x * np.arange(2,int(np.sqrt(n))))))\n  Ij_values = Ij.map(lambda x: ('not_prime', x[1])).reduceByKey(lambda p,q: p+q).collect()\n\n  def notin_(x):\n    if x not in list(dict(Ij_values)['not_prime']):\n      return x\n\n  prime_numbers = I.filter(lambda x: notin_(x))\n  return prime_numbers.take(n)\n\n# test for n = 100:\nprint('Prime numbers between 2-100 using the parallelized Eratosthenes') \nprint(Eratosthenes_sc(100))\nprint('')\n\n# compare with previouse ways to calculate for n = {10,100,...,10000000}:\n# RUN AND RECORD TIME\nwith Timer('Eratosthenes_sc, length: 10'):\n  Eratosthenes_sc(11)\n\nwith Timer('Eratosthenes_sc, length: 100'):\n  Eratosthenes_sc(101)\n\nwith Timer('Eratosthenes_sc, length: 1000'):\n  Eratosthenes_sc(1001)\n\nwith Timer('Eratosthenes_sc, length: 10000'):\n  Eratosthenes_sc(10001)\n\nwith Timer('Eratosthenes_sc, length: 100000'):\n  Eratosthenes_sc(100001)\n\nwith Timer('Eratosthenes_sc, length: 1000000'):\n  Eratosthenes_sc(1000001)\n\nwith Timer('Eratosthenes_sc, length: 10000000'):\n  Eratosthenes_sc(10000001)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00669397-a633-439b-8233-b112819a92ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Prime numbers between 2-100 using the parallelized Eratosthenes\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n\n[Eratosthenes_sc, length: 10]\nElapsed: 1.2735052108764648\n[Eratosthenes_sc, length: 100]\nElapsed: 1.275810956954956\n[Eratosthenes_sc, length: 1000]\nElapsed: 4.405946254730225\n[Eratosthenes_sc, length: 10000]\nElapsed: 555.108478307724\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Prime numbers between 2-100 using the parallelized Eratosthenes\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n\n[Eratosthenes_sc, length: 10]\nElapsed: 1.2735052108764648\n[Eratosthenes_sc, length: 100]\nElapsed: 1.275810956954956\n[Eratosthenes_sc, length: 1000]\nElapsed: 4.405946254730225\n[Eratosthenes_sc, length: 10000]\nElapsed: 555.108478307724\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Cancelled","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["*SOLUTION* <br>\nIn spite of parallelizing the algorithm, I was unable to improve the running times compared to the Python implementation from the previous subsection.  \nMy guess is that this is due to the `list()` I used that slowed the overall performance."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31049fcf-c8b6-4e64-8ff3-f6c426a77170"}}},{"cell_type":"markdown","source":["###  Part 2): Words Count with Spark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07d7628f-15b9-4f49-94c5-2e8c471d76ad"}}},{"cell_type":"code","source":["# Reading the book \"war and peace\"\ndbutils.fs.ls(\"/FileStore/tables/\") # Change to your path\nimport re # Regular expressions\n# Load the \"war and peace\" novel into RDD\nb = sc.textFile('/FileStore/tables/war_and_peace.txt')\n\n# A useful function for remiving any non-words and splitting lines into separate words\ndef splitter(line):\n    line = re.sub(r'^\\W+|\\W+$', '', line)\n    return (re.split(r'\\W+', line))\n\nb.take(10) # show first 10 lines"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"107e775c-f685-4f35-9107-bbc0fd0cf69b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: [&#39;&#39;,\n &#39;The Project Gutenberg EBook of War and Peace, by Leo Tolstoy&#39;,\n &#39;&#39;,\n &#39;This eBook is for the use of anyone anywhere at no cost and with almost&#39;,\n &#39;no restrictions whatsoever. You may copy it, give it away or re-use&#39;,\n &#39;it under the terms of the Project Gutenberg License included with this&#39;,\n &#39;eBook or online at www.gutenberg.org&#39;,\n &#39;&#39;,\n &#39;&#39;,\n &#39;Title: War and Peace&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [&#39;&#39;,\n &#39;The Project Gutenberg EBook of War and Peace, by Leo Tolstoy&#39;,\n &#39;&#39;,\n &#39;This eBook is for the use of anyone anywhere at no cost and with almost&#39;,\n &#39;no restrictions whatsoever. You may copy it, give it away or re-use&#39;,\n &#39;it under the terms of the Project Gutenberg License included with this&#39;,\n &#39;eBook or online at www.gutenberg.org&#39;,\n &#39;&#39;,\n &#39;&#39;,\n &#39;Title: War and Peace&#39;]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 1:** Upload the \"war and peace\" novel text file and change the path to match your account in the code above. <br> \nCount and print the total number of words and the number of lines in the file (any string separated by spaces is considered a word, even if it is a number, or another non-english-word string)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c0fe326-7921-4767-ac22-4747db2265c3"}}},{"cell_type":"code","source":["# SOLUTION\n\n# Number of words\nb_split = b.flatMap(lambda x : splitter(x))\n\n# Number of lines\nprint(f'total number of lines: {b.count()}')\n\n## Remove empty elements (lines)\ndef len_(x):\n  if len(x)>0:\n    return x\n  \nb_split_longerthan0 = b_split.filter(lambda x: len_(x))\nb_split_longerthan0.take(10)\n\nprint(f'total number of words: {b_split_longerthan0.count()}')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3be94c51-d463-47e7-910b-c35577004c1e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">total number of lines: 66053\ntotal number of words: 576638\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total number of lines: 66053\ntotal number of words: 576638\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 2:** Compute the number of times each word appears in the file. Ignore case (that is, for example `The` and `the` count as the same word). <br>\nPrint the 10 most frequent words, and the 10 longest words (together with their number of appearances for both)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1199baab-64cd-406a-a1a9-4aeb9f5155c8"}}},{"cell_type":"code","source":["# SOLUTION\nfrom operator import add \n\n# Convert all words in file to lowe cases\nb_lower = b_split.map(lambda x: x.lower())\n# remove spaces\nb_split_longerthan0 = b_lower.filter(lambda x: len_(x))\n\nhistogram = b_split_longerthan0.map(lambda x : (x,1)).reduceByKey(add)\n\nprint('10 most frequent words:')\nhistogram.sortBy(lambda x: x[1], ascending=False).take(10)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc7c0193-3a92-42e2-8ef2-015d27e932f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">10 most frequent words:\nOut[7]: [(&#39;the&#39;, 34725),\n (&#39;and&#39;, 22307),\n (&#39;to&#39;, 16757),\n (&#39;of&#39;, 15010),\n (&#39;a&#39;, 10583),\n (&#39;he&#39;, 10007),\n (&#39;in&#39;, 9036),\n (&#39;that&#39;, 8205),\n (&#39;his&#39;, 7984),\n (&#39;was&#39;, 7364)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">10 most frequent words:\nOut[7]: [(&#39;the&#39;, 34725),\n (&#39;and&#39;, 22307),\n (&#39;to&#39;, 16757),\n (&#39;of&#39;, 15010),\n (&#39;a&#39;, 10583),\n (&#39;he&#39;, 10007),\n (&#39;in&#39;, 9036),\n (&#39;that&#39;, 8205),\n (&#39;his&#39;, 7984),\n (&#39;was&#39;, 7364)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print('10 longest words:')\nhistogram.sortBy(lambda x: len(x[0]), ascending=False).take(10)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a6d35b2-c58e-4a78-ba7d-a5ac652fde3b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">10 longest words:\nOut[8]: [(&#39;characteristically&#39;, 3),\n (&#39;misunderstandings&#39;, 6),\n (&#39;unapproachability&#39;, 1),\n (&#39;superstitiousness&#39;, 1),\n (&#39;contemporaneously&#39;, 1),\n (&#39;enthusiastically&#39;, 3),\n (&#39;circumstantially&#39;, 1),\n (&#39;misunderstanding&#39;, 6),\n (&#39;superciliousness&#39;, 1),\n (&#39;melodramatically&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">10 longest words:\nOut[8]: [(&#39;characteristically&#39;, 3),\n (&#39;misunderstandings&#39;, 6),\n (&#39;unapproachability&#39;, 1),\n (&#39;superstitiousness&#39;, 1),\n (&#39;contemporaneously&#39;, 1),\n (&#39;enthusiastically&#39;, 3),\n (&#39;circumstantially&#39;, 1),\n (&#39;misunderstanding&#39;, 6),\n (&#39;superciliousness&#39;, 1),\n (&#39;melodramatically&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 3:** Compute the counts of consecutive **pairs** of words in the file. Ignore case. Ignore empty words. <br>\nThe order of words in the pair matters (that is, for example, the pair `she is` should be counted as a different pair form the paier `is she`). <br>\nPrint the 10 most frequent **pairs** of words together with their count"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e263be4-836d-4dca-a866-1fb8863242fa"}}},{"cell_type":"code","source":["# SOLUTION\n\n# create a list of consecutive words\ndef consec_(x):\n  res = [f'{x[i]} {x[i+1]}' for i in range(len(x) - 1)]\n  return res\n\nb_split_longerthan0_list = b_split_longerthan0.take(b_split_longerthan0.count())\nb_split_longerthan0_consec = consec_(b_split_longerthan0_list)\n\n# Convert list to RDD\nb_split_longerthan0_consec = spark.sparkContext.parallelize(b_split_longerthan0_consec)\n\n# Count order-sensitive paires\nhistogram = b_split_longerthan0_consec.map(lambda x : (x,1)).reduceByKey(add)\n\n# print\nprint('10 most frequent pairs:')\nhistogram.sortBy(lambda x: x[1], ascending=False).take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4923893c-0cb9-4e35-8d91-5757ad6c9a54"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">10 most frequent pairs:\nOut[9]: [(&#39;of the&#39;, 4061),\n (&#39;to the&#39;, 2334),\n (&#39;in the&#39;, 2331),\n (&#39;and the&#39;, 1474),\n (&#39;at the&#39;, 1350),\n (&#39;on the&#39;, 1336),\n (&#39;he had&#39;, 1219),\n (&#39;prince andrew&#39;, 1072),\n (&#39;did not&#39;, 1053),\n (&#39;he was&#39;, 957)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">10 most frequent pairs:\nOut[9]: [(&#39;of the&#39;, 4061),\n (&#39;to the&#39;, 2334),\n (&#39;in the&#39;, 2331),\n (&#39;and the&#39;, 1474),\n (&#39;at the&#39;, 1350),\n (&#39;on the&#39;, 1336),\n (&#39;he had&#39;, 1219),\n (&#39;prince andrew&#39;, 1072),\n (&#39;did not&#39;, 1053),\n (&#39;he was&#39;, 957)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 4:** Repeat the previous question, but this time count word pairs **unordered**. That is, occurances of `she is` and of `is she` should be counted as instances of the same pair. <br>\nWhen printing the top pairs, the two words should be ordered lexicographically (e.g. `is she` for the above example pair)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc4aa703-85bc-49ae-b42b-8f7a76a8df1b"}}},{"cell_type":"code","source":["# SOLUTION\ndef consec_unordered_(x):\n  res = [str(set([x[i], x[i+1]])) for i in range(len(x) - 1)]\n  res = [re.sub('[^a-zA-Z ]+', '', res[i]) for i in range(len(res))]\n  return res\n\n# Create consecutive paires\nb_split_consec_unordered =  consec_unordered_(b_split_longerthan0_list)\n\n# Convert list to RDD\nb_split_consec_unordered = spark.sparkContext.parallelize(b_split_consec_unordered)\n\n# Count order-insensitive paires\nhistogram = b_split_consec_unordered.map(lambda x : (x,1)).reduceByKey(add)\n\n# print\nprint('10 most frequent pairs:')\nhistogram.sortBy(lambda x: x[1], ascending=False).take(10)\n\n# NOTE: We see that the table below differs from the one of the last subsection in cases which both words can come second, such as \"did not\" and \"not did\", or \"he was\" and \"was he\". Because the changes were not significant, I added abother example below. The example shows that consec_unordered_ does work as we were asked."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df5ca5cd-b5f7-494e-9176-138b2b845a42"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">10 most frequent pairs:\nOut[10]: [(&#39;of the&#39;, 4061),\n (&#39;the to&#39;, 2334),\n (&#39;in the&#39;, 2331),\n (&#39;the and&#39;, 1474),\n (&#39;at the&#39;, 1350),\n (&#39;the on&#39;, 1336),\n (&#39;he had&#39;, 1269),\n (&#39;prince andrew&#39;, 1074),\n (&#39;did not&#39;, 1054),\n (&#39;he was&#39;, 990)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">10 most frequent pairs:\nOut[10]: [(&#39;of the&#39;, 4061),\n (&#39;the to&#39;, 2334),\n (&#39;in the&#39;, 2331),\n (&#39;the and&#39;, 1474),\n (&#39;at the&#39;, 1350),\n (&#39;the on&#39;, 1336),\n (&#39;he had&#39;, 1269),\n (&#39;prince andrew&#39;, 1074),\n (&#39;did not&#39;, 1054),\n (&#39;he was&#39;, 990)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["temp =  consec_unordered_(['a', 'dog', 'ate', 'dog', 'a', 'list', 'word'])\n\n# Convert list to RDD\ntemp = spark.sparkContext.parallelize(temp)\n\n# Count order-insensitive paires\nhistogram = temp.map(lambda x : (x,1)).reduceByKey(add)\n\n# print\nprint('Pairs:')\nhistogram.sortBy(lambda x: x[1], ascending=False).take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bf958a2-d9e1-45dd-8988-2e6a88adfe66"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Pairs:\nOut[11]: [(&#39;a dog&#39;, 2), (&#39;dog ate&#39;, 2), (&#39;a list&#39;, 1), (&#39;list word&#39;, 1)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Pairs:\nOut[11]: [(&#39;a dog&#39;, 2), (&#39;dog ate&#39;, 2), (&#39;a list&#39;, 1), (&#39;list word&#39;, 1)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Question 5:** Get for each word the number of times it appears with the first letter being in upper/lower case, separately, such that each word will have two counts associated with it. <br>\nFor example, for the word `The` count seperately the occurances of `The` (and also, for example `THE`) and the occurances of `the` (and also `tTe`, `tHE` ..). <br>\nNext, filter and keep only words appearing with the first letter being both uppercase and lowercase at least once in the file. Sort these words by their uppercase count / lowercase count ratio. <br>\nFinally, print the 10 words with the **highest** ratio (together with the number of appearances in uppercase and lowercase), and similarly the 10 words with the **lowest** ratio. <br>\nAre the results expected/surprising?"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae544e94-9e76-47dc-a7cf-e7928d94667f"}}},{"cell_type":"code","source":["# SOLUTION\ndef first_letter_lower_(x):\n  if x[0] == x[0].lower():\n    return x\ndef first_letter_upper_(x):\n  if x[0] == x[0].upper():\n    return x\n\n# Remove spaces and lines\nb_split_longerthan0 = b_split.filter(lambda x: len_(x))\nprint('first 15 words on war and peace file:')\nprint(b_split_longerthan0.take(15))\nprint('')\n\n# Keep only words that start with a lower letter\nb_split_longerthan0_lower = b_split_longerthan0.filter(lambda x: first_letter_lower_(x))\nprint('Only words that start with a lower letter:')\nprint(b_split_longerthan0_lower.take(10))\nprint('')\n\n# Keep only words that start with a lower letter\nb_split_longerthan0_upper = b_split_longerthan0.filter(lambda x: first_letter_upper_(x))\nprint('Only words that start with an upper letter:')\nprint(b_split_longerthan0_upper.take(10))\nprint('')\n\n# Count for each word\nhistogram_lower = b_split_longerthan0_lower.map(lambda x : (x,1)).reduceByKey(add)\nhistogram_upper = b_split_longerthan0_upper.map(lambda x : (x,1)).reduceByKey(add)\n\n# Now, in order to join the two RDD, I use lower cases\nhistogram_upper_lower =  histogram_upper.map(lambda x: (x[0].lower(), x[1]))\n## collect cases like THE and THe now they have turnd into the\nhistogram_upper_lower = histogram_upper_lower.map(lambda x : (x[0],x[1])).reduceByKey(add)\n\n# perform inner join\njoint = sorted(histogram_lower.join(histogram_upper_lower).collect())\njoint = spark.sparkContext.parallelize(joint)\n\n# Filter out \"words\" that start with numbers\ndef first_letter_number_(x):\n  if not x[0][0].isnumeric():\n    return x\n\njoint = joint.filter(lambda x: first_letter_number_(x))\n\n# Compute ratio, sort, and present first 10\nratio = joint.map(lambda x: (x[0], x[1][1]/x[1][0]))\n\n# NOTE: To my understanding, even though we filter the words by the ratio\n# of uppercase/lowercase appearences, we shoud present ONLY the words,\n# the upper case appearences and the lower case ones. So even though I \n# calculate it, I remove it from the results. If I was wrong, please \n# consider that I did calculate the ratio.\n\n# Keep the 10 highest ratio words\nhighest_ratio = ratio.sortBy(lambda x: x[1], ascending=False).take(10)\nhighest_ratio = spark.sparkContext.parallelize(highest_ratio)\nhighest_ratio = highest_ratio.map(lambda x: (x[0], 0))\n\n# Keep the 10 lowes ratio words\nlowest_ratio = ratio.sortBy(lambda x: x[1], ascending=True).take(10)\nlowest_ratio = spark.sparkContext.parallelize(lowest_ratio)\nlowest_ratio = lowest_ratio.map(lambda x: (x[0], 0))\n\n# Join highest_ratio with number of appearences in upper case and lower case\nhighest_results = highest_ratio.join(histogram_upper_lower).collect()\nhighest_results = spark.sparkContext.parallelize(highest_results)\nhighest_results = highest_results.map(lambda x: (x[0], x[1][1]))\nhighest_results = highest_results.join(histogram_lower).collect()\nprint('10 words with the highest uppercase/lowercase appearences:')\nprint('The format of the following table is (name, (upper case, lower case))')\nhighest_results\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10bdbd6b-a154-4cff-8d46-4859ebc9e4b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">first 15 words on war and peace file:\n[&#39;The&#39;, &#39;Project&#39;, &#39;Gutenberg&#39;, &#39;EBook&#39;, &#39;of&#39;, &#39;War&#39;, &#39;and&#39;, &#39;Peace&#39;, &#39;by&#39;, &#39;Leo&#39;, &#39;Tolstoy&#39;, &#39;This&#39;, &#39;eBook&#39;, &#39;is&#39;, &#39;for&#39;]\n\nOnly words that start with a lower letter:\n[&#39;of&#39;, &#39;and&#39;, &#39;by&#39;, &#39;eBook&#39;, &#39;is&#39;, &#39;for&#39;, &#39;the&#39;, &#39;use&#39;, &#39;of&#39;, &#39;anyone&#39;]\n\nOnly words that start with an upper letter:\n[&#39;The&#39;, &#39;Project&#39;, &#39;Gutenberg&#39;, &#39;EBook&#39;, &#39;War&#39;, &#39;Peace&#39;, &#39;Leo&#39;, &#39;Tolstoy&#39;, &#39;This&#39;, &#39;You&#39;]\n\n10 words with the highest uppercase/lowercase appearences:\nThe format of the following table is (name, (upper case, lower case))\nOut[122]: [(&#39;mamma&#39;, (105, 2)),\n (&#39;papa&#39;, (48, 1)),\n (&#39;lord&#39;, (51, 2)),\n (&#39;i&#39;, (4540, 1)),\n (&#39;polish&#39;, (42, 1)),\n (&#39;st&#39;, (40, 1)),\n (&#39;chapter&#39;, (730, 2)),\n (&#39;oh&#39;, (304, 13)),\n (&#39;emperor&#39;, (625, 6)),\n (&#39;v&#39;, (38, 1))]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">first 15 words on war and peace file:\n[&#39;The&#39;, &#39;Project&#39;, &#39;Gutenberg&#39;, &#39;EBook&#39;, &#39;of&#39;, &#39;War&#39;, &#39;and&#39;, &#39;Peace&#39;, &#39;by&#39;, &#39;Leo&#39;, &#39;Tolstoy&#39;, &#39;This&#39;, &#39;eBook&#39;, &#39;is&#39;, &#39;for&#39;]\n\nOnly words that start with a lower letter:\n[&#39;of&#39;, &#39;and&#39;, &#39;by&#39;, &#39;eBook&#39;, &#39;is&#39;, &#39;for&#39;, &#39;the&#39;, &#39;use&#39;, &#39;of&#39;, &#39;anyone&#39;]\n\nOnly words that start with an upper letter:\n[&#39;The&#39;, &#39;Project&#39;, &#39;Gutenberg&#39;, &#39;EBook&#39;, &#39;War&#39;, &#39;Peace&#39;, &#39;Leo&#39;, &#39;Tolstoy&#39;, &#39;This&#39;, &#39;You&#39;]\n\n10 words with the highest uppercase/lowercase appearences:\nThe format of the following table is (name, (upper case, lower case))\nOut[122]: [(&#39;mamma&#39;, (105, 2)),\n (&#39;papa&#39;, (48, 1)),\n (&#39;lord&#39;, (51, 2)),\n (&#39;i&#39;, (4540, 1)),\n (&#39;polish&#39;, (42, 1)),\n (&#39;st&#39;, (40, 1)),\n (&#39;chapter&#39;, (730, 2)),\n (&#39;oh&#39;, (304, 13)),\n (&#39;emperor&#39;, (625, 6)),\n (&#39;v&#39;, (38, 1))]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Join highest_ratio with number of appearences in upper case and lower case\nlowest_results = lowest_ratio.join(histogram_upper_lower).collect()\nlowest_results = spark.sparkContext.parallelize(lowest_results)\nlowest_results = lowest_results.map(lambda x: (x[0], x[1][1]))\nlowest_results = lowest_results.join(histogram_lower).collect()\nprint('10 words with the lowest uppercase/lowercase incidencts:')\nprint('The format of the following table is (name, (upper case, lower case))')\nlowest_results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1db8a31-a8c0-46a5-89a6-adbd3baf7c07"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">10 words with the lowest uppercase/lowercase incidencts:\nThe format of the following table is (name, (upper case, lower case))\nOut[123]: [(&#39;eyes&#39;, (1, 826)),\n (&#39;away&#39;, (1, 616)),\n (&#39;head&#39;, (1, 567)),\n (&#39;way&#39;, (1, 493)),\n (&#39;t&#39;, (2, 1157)),\n (&#39;came&#39;, (1, 682)),\n (&#39;saw&#39;, (1, 462)),\n (&#39;been&#39;, (2, 1474)),\n (&#39;thought&#39;, (1, 766)),\n (&#39;went&#39;, (1, 861))]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">10 words with the lowest uppercase/lowercase incidencts:\nThe format of the following table is (name, (upper case, lower case))\nOut[123]: [(&#39;eyes&#39;, (1, 826)),\n (&#39;away&#39;, (1, 616)),\n (&#39;head&#39;, (1, 567)),\n (&#39;way&#39;, (1, 493)),\n (&#39;t&#39;, (2, 1157)),\n (&#39;came&#39;, (1, 682)),\n (&#39;saw&#39;, (1, 462)),\n (&#39;been&#39;, (2, 1474)),\n (&#39;thought&#39;, (1, 766)),\n (&#39;went&#39;, (1, 861))]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**SOLUTION** <br>\nOverall, I think the results we have obtained are not surprising. There are some verbs among the 10 words ranked with the lowest ratio. It is less common to begin a sentence with a verb, so verb ratios are expected to be lower.  \nBy contrast, \"i\" got the highest score (4540/1), as expected. \"Chapter\" appears with a rank of (730/2), which makes sense, since it denotes the beginning of a new chapter. In general, most of the top 10 words are adjectives, which makes sense. \"Lord\", \"Papa\", \"St.\"; these are all acceptable openings, and considering the time period covered in \"War and Peace\", they may even be expected."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b674c869-a817-4ae1-9e07-2274f866d4a7"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PS3 SPARK","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3978726733563410}},"nbformat":4,"nbformat_minor":0}
